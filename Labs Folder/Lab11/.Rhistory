#| include: false
# load packages
library(tidyverse)
library(kableExtra)
library(broom)
library(microbenchmark)
install.packages("microbenchmark")
#| include: false
# load packages
library(tidyverse)
library(kableExtra)
library(broom)
library(microbenchmark)
library(plotly)
# set code chunk defaults
knitr::opts_chunk$set(tidy = F, # display code as typed
size = "small", # slightly smaller code font
message = FALSE,
warning = FALSE,
comment = "\t")
# set black & white default plot theme
theme_set(theme_classic())
# improve digit and NA display
options(scipen = 1, knitr.kable.NA = '')
for (i in 1:10){
print(10*i)
}
10*1:10
seq(10, 30, by = 5)
seq(20,40, by = 2)
# specify vector to iterate over
mycolors <- c("turquoise", "burgundy", "navy blue")
# Print sentence, iterating over colors in vector
for (j in mycolors){
cat(paste0("My favorite color is ", j, "!\n"))
}
# Initialize empty vector and view it
(vec <- rep(NA, 10))
# Fill vector as you iterate
for (i in 1:10){
vec[i] <- 10*i
}
# What's in vec now?
vec
# Shorter vectorized version
(vec <- 10*1:10)
# Initialize empty vector and view it
(vec <- rep(NA, 10))
# Fill vector as you iterate
for (i in 1:10){
vec[i] <- 10*i
}
# What's in vec now?
vec
# Shorter vectorized version
(vec <- 10*1:10)
#| label: plot-normal
set.seed(231)
# Vector of values from Normal distribution
norm_vec <- rnorm(n = 1000, mean = 10, sd = 2)
# Plot of generated values (vector must be dataframe for use with ggplot)
ggplot(data.frame(norm_vec), aes(x = norm_vec, y = ..density..)) +
geom_histogram(color = "black", fill = "grey") +
geom_density(size = 1) +
labs(x = "x",
title = "Values generated from Normal distribution",
subtitle = "Mean = 10; SD = 2")
#| label: plot-normal
set.seed(231)
# Vector of values from Normal distribution
norm_vec <- rnorm(n = 1000, mean = 10, sd = 2)
# Plot of generated values (vector must be dataframe for use with ggplot)
ggplot(data.frame(norm_vec), aes(x = norm_vec, y = ..density..)) +
geom_histogram(color = "black", fill = "grey") +
geom_density(size = 1) +
labs(x = "x",
title = "Values generated from Normal distribution",
subtitle = "Mean = 10; SD = 2")
#| label: generate-mvn
set.seed(231)
# Specify 2-dimensional mean vector
# first variable mean is 0, second variable mean is 2
# if you wanted both to be 0, could do rep(0, 2)
(mean_vector <- c(0, 2))
# Specify 2x2 identity matrix as the covariance matrix
# This means the variables are uncorrelated and each has variance of 1
(covariance_matrix <- diag(2))
## Alternative equivalent specification of the 2x2 covariance matrix, independent vars:
(covariance_matrix <- matrix(c(1, 0, 0, 1), nrow = 2))
# Generate a single observation from bivariate Normal dist
MASS::mvrnorm(n = 1, mu = mean_vector, Sigma = covariance_matrix)
# Generate 5 observations from bivariate Normal dist
MASS::mvrnorm(n = 5, mu = mean_vector, Sigma = covariance_matrix) %>%
data.frame()
#| label: plot-uniform
set.seed(8)
# Vector of values from Uniform distribution
unif_vec <- runif(n = 1000, min = 5, max = 10)
# Plot of generated values (vector must be dataframe for use with ggplot)
ggplot(data.frame(unif_vec), aes(x = unif_vec, y = ..density..)) +
geom_histogram(color = "black", fill = "grey") +
geom_density(size = 1) +
labs(x = "x",
title = "Values generated from Uniform distribution",
subtitle = "Min = 5; Max = 10")
#| label: plot-exponential
set.seed(8)
# Vector of values from Exponential distribution
exp_vec <- rexp(n = 1000, rate = 2)
# Plot of generated values (vector must be dataframe for use with ggplot)
ggplot(data.frame(exp_vec), aes(x = exp_vec, y = ..density..)) +
geom_histogram(color = "black", fill = "grey") +
geom_density(size = 1) +
labs(x = "x",
title = "Values generated from Exponential distribution",
subtitle = "Rate = 2")
#| label: plot-exponential
set.seed(8)
# Vector of values from Exponential distribution
exp_vec <- rexp(n = 1000, rate = 2)
# Plot of generated values (vector must be dataframe for use with ggplot)
ggplot(data.frame(exp_vec), aes(x = exp_vec, y = ..density..)) +
geom_histogram(color = "black", fill = "grey") +
geom_density(size = 1) +
labs(x = "x",
title = "Values generated from Exponential distribution",
subtitle = "Rate = 2")
#| label: plot-poisson
set.seed(8)
# Vector of values from Poisson distribution
pois_vec <- rpois(n = 1000, lambda = 1)
# Plot of generated values (vector must be dataframe for use with ggplot)
ggplot(data.frame(pois_vec), aes(x = pois_vec)) +
geom_bar(color = "black", fill = "grey") +
labs(x = "x",
title = "Values generated from Poisson distribution",
subtitle = "Lambda = 1")
#| label: gen-mvn
set.seed(86)
# Specify 2-dimensional mean vector
(mean_vector <- c(0, 2))
# Specify 2x2 identity matrix as the covariance matrix
(covariance_matrix <- diag(2))
# Generate 5000 observations and create data frame for use with ggplot()
mvn_matrix <- MASS::mvrnorm(n = 5000, mu = mean_vector, Sigma = covariance_matrix) %>%
data.frame()
#| label: plot-mvn-density
#| eval: false
# Estimate kernel density from generated data
mvn_3d <- MASS::kde2d(x = mvn_matrix$X1, y = mvn_matrix$X2)
# Create 3D density plot
plot_ly(x = mvn_3d$x, y = mvn_3d$y, z = mvn_3d$z) %>%
add_surface()
#| label: mvn-contour-plot
# 2-D contour plot with ggplot
ggplot(mvn_matrix, aes(x = X1, y = X2)) +
geom_density_2d()
#| label: mvn-scatterplot
# Visualize association
ggplot(mvn_matrix, aes(x = X1, y = X2)) +
geom_point(alpha = 0.3)
# Estimate correlation
summarize(mvn_matrix, cor = cor(X1, X2))
#| label: mvn-scatterplot
# Visualize association
ggplot(mvn_matrix, aes(x = X1, y = X2)) +
geom_point(alpha = 0.3)
# Estimate correlation
summarize(mvn_matrix, cor = cor(X1, X2))
# Plot marginal distribution of X1
ggplot(mvn_matrix, aes(x = X1)) +
geom_density()
# Plot marginal distribution of X2
ggplot(mvn_matrix, aes(x = X2)) +
geom_density()
#| label: sampling-distrn
set.seed(2021)
# Simulation size
n_sim <- 1000
# Number of observations in each random sample
n_obs <- 250
# Initialize empty vector to store results
means <- rep(NA, n_sim)
for (i in 1:n_sim){
# Generate sample of Normal data
dat <- rnorm(n_obs, mean = 10, sd = 2)
# Compute sample mean
means[i] <- mean(dat)
}
# Plot empirical sampling distribution of the sample mean
ggplot(data.frame(means), aes(x = means)) +
geom_histogram(color = "black", fill = "grey") +
lims(x = c(9, 11)) +
labs(x = "Sample mean",
y = "Number of samples")
#| label: simple-sim
# Set the seed for reproducibility!
set.seed(231)
#############################
# Set simulation parameters #
#############################
# Simulation size
n_sim <- 1000
# Number of observations in each random sample
n_obs <- 250
##############################
# Steps for single iteration #
##############################
# Generate predictor
x <- rnorm(n = n_obs, mean = 0, sd = 1)
# Generate outcome (independent of x)
y <- rnorm(n = n_obs, mean = 0, sd = 1)
# Fit simple linear regression model
mod <- lm(y ~ x)
# Extract p-value for predictor
pvalue <- mod %>%
# Use tidy() from broom package to make p-values easy to extract
broom::tidy() %>%
filter(term == "x") %>%
pull(p.value)
#############################################
# Simulate!                                 #
# (repeat many times and summarize results) #
#############################################
# Initialize vector for storing the simulated p-values
pvalues <- rep(NA, n_sim)
for(i in 1:n_sim){
# Generate predictor
x <- rnorm(n = n_obs, mean = 0, sd = 1)
# Generate outcome (independent of x)
y <- rnorm(n = n_obs, mean = 0, sd = 1)
# Fit single bivariate model
mod <- lm(y ~ x)
# Extract p-value for predictor
pvalues[i] <- mod %>%
# Use tidy() from broom package to make p-values easy to extract
broom::tidy() %>%
filter(term == "x") %>%
pull(p.value)
}
# Generate target visualization: histogram of p-values
# When null is true, sampling dist of p-value is Uniform(0, 1)
ggplot(data.frame(pvalues), aes(x = pvalues)) +
geom_histogram(color = "black", fill = "grey") +
# Represent significance level cut-off
geom_vline(xintercept = 0.05, color = "red") +
labs(x = "p-value", y = "Number of samples")
# Generate target summary: empirical type I error rate
# Given null is true, should be around 5%
data.frame(pvalues) %>%
mutate(sig_05 = ifelse(pvalues < 0.05, 1, 0)) %>%
summarize(n_sim = n(), empirical_t1error = mean(sig_05))
#| label: build-up
#| cache: true
# Set the seed for reproducibility
set.seed(231)
#############################
# Set simulation parameters #
#############################
# Simulation size
n_sim <- 1000
# Number of observations in each random sample
n_obs <- 250
# Number of predictor variables
n_x <- 100
##############################
# Steps for single iteration #
##############################
# Generate 100 predictors from multivariate Normal distribution
xs <- MASS::mvrnorm(n = n_obs, mu = rep(0, n_x), Sigma = diag(n_x)) %>%
data.frame()
# Generate outcome (independent of the 100 predictors)
dat <- xs %>%
mutate(y = rnorm(n = n_obs, mean = 0, sd = 1))
# Fit 100 different simple linear regression models (one model for each predictor)
# and extract p-values
pvalues <- rep(NA, n_x)
for (j in 1:n_x){
# Fit model
mod <- lm(formula = paste0("y ~ X", j), data = dat)
# Extract p-value for predictor (tidy)
# pvalues[j] <- mod %>%
#   # Use tidy() from broom package to make p-values easy to extract
#   broom::tidy() %>%
#   filter(term == paste0("X", j)) %>%
#   pull(p.value)
# Extract p-value (base R is faster in this case)
pvalues[j] <- (summary(mod)$coeff)[paste0("X", j), "Pr(>|t|)"]
}
#############################################
# Simulate!                                 #
# (repeat many times and summarize results) #
#############################################
# Initialize matrix for storing the p-values
# - Columns will be predictors X1-X100
# - Rows will be the different iterations, 1 per n_sim
# - There are two `for` loops, notice how we used j for the index above?
pvalues <- array(NA, dim = c(n_sim, n_x)) %>% data.frame()
for (i in 1:n_sim){
# Generate 100 predictors from multivariate Normal distribution
xs <- MASS::mvrnorm(n = n_obs, mu = rep(0, n_x), Sigma = diag(n_x)) %>%
data.frame()
# Generate outcome (independent of the 100 predictors)
dat <- xs %>%
mutate(y = rnorm(n = n_obs, mean = 0, sd = 1))
# Fit 100 different bivariate models (one model for each predictor)
# and extract p-values
for (j in 1:n_x){
# Fit model
mod <- lm(formula = paste0("y ~ X", j), data = dat)
# Extract p-value using base R method
pvalues[i, j] <- (summary(mod)$coeff)[paste0("X", j), "Pr(>|t|)"]
}
}
# Generate target visualization for Q1: histogram of p-values for X1
# - When null is true, sampling dist of p-value is Uniform(0, 1)
ggplot(data.frame(pvalues), aes(x = X1)) +
geom_histogram(color = "black", fill = "grey") +
# Represent significance level cut-off
geom_vline(xintercept = 0.05, color = "red") +
labs(x = "p-value", y = "Number of samples")
# Generate target summary for Q2: empirical type I error rates for each predictor
# - Given null is true, should be around 5% each
pvalues <- data.frame(pvalues) %>%
# check whether each p-value is less than 0.05 (significant = 1), and
# use across() to repeat check across every column
mutate(across(everything(), ~ ifelse(. < 0.05, 1, 0), .names = "{.col}_sig"))
(error_rates <- pvalues %>%
# compute proportion of p-values that are significant for every column
summarize(across(ends_with("_sig"), mean)))
# Generate target summary for Q3: probability at least 1 of 100 predictors is significant
# - each row represents one iteration;
# - need to see how many rows have at least one significant p-value
# - expect P(at least one) = 1 - P(none) = 1 - (0.95)^100 = 0.994
pvalues %>%
# must invoke `rowwise()` in order to use `sum()` across rows
rowwise() %>%
# check if the total number significant in each row is greater than 0
mutate(sum_sig = sum(c_across(ends_with("_sig"))),
any_sig = ifelse(sum_sig > 0, 1, 0)) %>%
# stop row-wise calculations
ungroup() %>%
# compute proportion of rows with at least one significant p-value
summarize(n_sim = n(),
prop_sims_sig = mean(any_sig))
#| label: build-up
#| cache: true
# Set the seed for reproducibility
set.seed(231)
#############################
# Set simulation parameters #
#############################
# Simulation size
n_sim <- 1000
# Number of observations in each random sample
n_obs <- 250
# Number of predictor variables
n_x <- 100
##############################
# Steps for single iteration #
##############################
# Generate 100 predictors from multivariate Normal distribution
xs <- MASS::mvrnorm(n = n_obs, mu = rep(0, n_x), Sigma = diag(n_x)) %>%
data.frame()
# Generate outcome (independent of the 100 predictors)
dat <- xs %>%
mutate(y = rnorm(n = n_obs, mean = 0, sd = 1))
# Fit 100 different simple linear regression models (one model for each predictor)
# and extract p-values
pvalues <- rep(NA, n_x)
for (j in 1:n_x){
# Fit model
mod <- lm(formula = paste0("y ~ X", j), data = dat)
# Extract p-value for predictor (tidy)
# pvalues[j] <- mod %>%
#   # Use tidy() from broom package to make p-values easy to extract
#   broom::tidy() %>%
#   filter(term == paste0("X", j)) %>%
#   pull(p.value)
# Extract p-value (base R is faster in this case)
pvalues[j] <- (summary(mod)$coeff)[paste0("X", j), "Pr(>|t|)"]
}
#############################################
# Simulate!                                 #
# (repeat many times and summarize results) #
#############################################
# Initialize matrix for storing the p-values
# - Columns will be predictors X1-X100
# - Rows will be the different iterations, 1 per n_sim
# - There are two `for` loops, notice how we used j for the index above?
pvalues <- array(NA, dim = c(n_sim, n_x)) %>% data.frame()
for (i in 1:n_sim){
# Generate 100 predictors from multivariate Normal distribution
xs <- MASS::mvrnorm(n = n_obs, mu = rep(0, n_x), Sigma = diag(n_x)) %>%
data.frame()
# Generate outcome (independent of the 100 predictors)
dat <- xs %>%
mutate(y = rnorm(n = n_obs, mean = 0, sd = 1))
# Fit 100 different bivariate models (one model for each predictor)
# and extract p-values
for (j in 1:n_x){
# Fit model
mod <- lm(formula = paste0("y ~ X", j), data = dat)
# Extract p-value using base R method
pvalues[i, j] <- (summary(mod)$coeff)[paste0("X", j), "Pr(>|t|)"]
}
}
# Generate target visualization for Q1: histogram of p-values for X1
# - When null is true, sampling dist of p-value is Uniform(0, 1)
ggplot(data.frame(pvalues), aes(x = X1)) +
geom_histogram(color = "black", fill = "grey") +
# Represent significance level cut-off
geom_vline(xintercept = 0.05, color = "red") +
labs(x = "p-value", y = "Number of samples")
# Generate target summary for Q2: empirical type I error rates for each predictor
# - Given null is true, should be around 5% each
pvalues <- data.frame(pvalues) %>%
# check whether each p-value is less than 0.05 (significant = 1), and
# use across() to repeat check across every column
mutate(across(everything(), ~ ifelse(. < 0.05, 1, 0), .names = "{.col}_sig"))
(error_rates <- pvalues %>%
# compute proportion of p-values that are significant for every column
summarize(across(ends_with("_sig"), mean)))
# Generate target summary for Q3: probability at least 1 of 100 predictors is significant
# - each row represents one iteration;
# - need to see how many rows have at least one significant p-value
# - expect P(at least one) = 1 - P(none) = 1 - (0.95)^100 = 0.994
pvalues %>%
# must invoke `rowwise()` in order to use `sum()` across rows
rowwise() %>%
# check if the total number significant in each row is greater than 0
mutate(sum_sig = sum(c_across(ends_with("_sig"))),
any_sig = ifelse(sum_sig > 0, 1, 0)) %>%
# stop row-wise calculations
ungroup() %>%
# compute proportion of rows with at least one significant p-value
summarize(n_sim = n(),
prop_sims_sig = mean(any_sig))
#| warning: false
#| message: false
# fit example multiple regression
test_model <- lm(y ~ X23 + X47 + X54, data = dat)
mosaic::msummary(test_model)
# Confirm p-value matches the p-value on the last line of the summary output
broom::glance(test_model)$p.value
#| warning: false
#| message: false
# fit example multiple regression
test_model <- lm(y ~ X23 + X47 + X54, data = dat)
mosaic::msummary(test_model)
# Confirm p-value matches the p-value on the last line of the summary output
broom::glance(test_model)$p.value
