#| include: false
# load packages
library(tidyverse)
library(kableExtra)
library(janitor)
library(tidytext)
library(wordcloud)
library(textdata)
# set code chunk defaults
knitr::opts_chunk$set(tidy = F, # display code as typed
size = "small", # slightly smaller code font
message = FALSE,
warning = FALSE,
comment = "\t")
# set black & white default plot theme
theme_set(theme_classic())
# improve digit and NA display
options(scipen = 1, knitr.kable.NA = '')
#| label: get-data
# Load dataset and name it "poems" for easier reference
poems <- readRDS("DickinsonPoems.Rds")
#| eval: false
mydata <- read_csv("my-data.csv")
poems_words_all <- poems %>%
unnest_tokens(output = word, input = text)
#| label: alt-tokens
poems_ngrams <- poems %>%
unnest_tokens(output = bigram, input = text,
token = "ngrams", n = 2)
data(stop_words)
# First, take a look at the stop_words dataset
head(stop_words)
tail(stop_words)
stop_words %>%
count(lexicon)
# Create new dataset since we are removing words
poems_words <- poems_words_all %>%
anti_join(stop_words, by = "word")
# Explore which stop words were removed
## If you don't want all these words removed, you can modify
## the stop_words dataframe before `anti_join`ing
removed <- poems_words_all %>%
anti_join(poems_words, by = "word") %>%
count(word) %>%
arrange(word)
View(removed)
View(stop_words)
View(stop_words)
#| label: top-words-plot1
poems_words |>
count(word, sort = TRUE) |>
slice(1:10) |>
# fct_reorder is used to re-order the axis (displaying the word)
# by values of n (the number of times that word was used)
ggplot(aes(x = fct_reorder(word, n), y = n, color = word, fill = word)) +
geom_col() +
# Rotate graph
coord_flip() +
guides(color = "none",
fill = "none") +
labs(
# Remove x variable label; notice that although coordinates are flipped,
# the labels correspond to which variables were specified
# as `x` and `y` in `aes()`
x = NULL,
y = "Number of instances",
title = "The most common words in Emily Dickinson's poems")
poems_words_all %>%
count(word, sort = TRUE) %>%
slice(1:10) %>%
ggplot(aes(x = fct_reorder(word,n), y = n, color = word, fill = word)) +
geom_col() +
coord_flip() +
guides(color = "none", fill = "none") +
labs(x = NULL, y = "Number of instances", title = "The most common words in Emily Dickinson's poems")
word_frequencies <- poems %>%
unnest_tokens(output = word, input = text) %>%
anti_join(stop_words, by = "word") %>%
count(word, sort = TRUE)
?unnest_tokens
bigram_frequencies <- poems %>%
unnest_tokens(output = bigram, input = text,
token = "ngrams", n = 2) %>%
anti_join(stop_words, by = "bigram")
bigram_frequencies <- poems %>%
unnest_tokens(output = bigram, input = text,
token = "ngrams", n = 2)
poems_bigram_clean <- bigram_frequencies %>%
separate(col = "bigram", into=c("word1","word2"), sep= " ", remove = FALSE) %>%
anti_join(stop_words, by=c("word1" = "word")) %>%
anti_join(stop_words, by=c("word2" = "word")) %>%
filter(!is.na(bigram)) %>%
count(bigram, sort = TRUE) %>%
slice(1:10)
head(poems_bigram_clean) %>%
kable()
#| label: basic-word-cloud
#| fig.height: 5
# Word cloud will rearrange each time unless seed is set
# Seed is set before each call to wordcloud, generates 3 identical clouds
# Preferred syntax, closest to class coding style we can get
# Using pipes with *with*
set.seed(231)
word_frequencies %>%
with(wordcloud(words = word, freq = n, max.words = 50))
# *With* syntax without pipes
set.seed(231)
with(word_frequencies, wordcloud(words = word, freq = n, max.words = 50))
# Using base R to reference variables directly
set.seed(231)
wordcloud(words = word_frequencies$word,
freq = word_frequencies$n,
max.words = 50)
# choose color palette from color brewer
mypal <- brewer.pal(10, "Paired")
set.seed(231)
word_frequencies %>%
with(wordcloud(words = word,
freq = n,
min.freq = 20,
max.words = 50,
# plot the words in a random order
random.order = TRUE,
# specify the range of the size of the words
scale = c(2, 0.3),
# specify proportion of words with 90 degree rotation
rot.per = 0.15,
# colors words from least to most frequent
colors = mypal,
# font family
family = "sans"))
# Type "Yes" to download if prompted
afinn_lexicon <- get_sentiments("afinn")
#| eval: false # remove this eval: false when compiling
# assumes you called the nrc lexicon nrc_lexicon, as asked above
nrc_missed_words <- word_frequencies %>%
anti_join(nrc_lexicon, by = "word")
# Type "Yes" to download if prompted
afinn_lexicon <- get_sentiments("nrc")
