# Note:
# i. these could be based on either start datetime or end datetime
# ii. you do NOT need all of these!! so only use what you need
date = date(start),
year = year(start),
month_number = month(start),
month_label = month(start,
label = TRUE,
abbr = FALSE),
weekday_number = wday(start),
weekday_label = wday(start,
label = TRUE,
abbr = FALSE),
hour = hour(start),
time = hour(start) + minute(start)/60,
# Convert text to lowercase and remove repeated or leading/trailing
# spaces to help clean up inconsistent formatting.
across(c(activity, description),
.fns = str_to_lower),
across(c(activity, description),
.fns = str_squish)
) %>%
# The first Google Calendar entry is always an empty 1969 event
filter(year != 1969)
# I have divided my wrangling code into various wrangling sections. The first
# one below is general wrangling code that allows me to select the columns I
# need for my first visualisation and the second one
# (i.e duration spent on activities at home & cumulative time on activities)
wrangled_mycal <- mycal %>%
select(activity, description, duration_hours) %>%
rename(
Activity = activity, Location = description, Duration = duration_hours)
wrangled_mycal$Duration = round(wrangled_mycal$Duration, 3)
#wrangling for first visualisation
homeActivities_plot <- wrangled_mycal %>%
filter(
Activity %in% c("job",
"math211homework",
"physics124homework",
"cosc112homework",
"stat231homework")
) %>%
na.omit()
#Making sure to omit any entries where there was no coursework or
#data was incomplete or missing
#Our second visualisation is in the form of a bar chart, so we must wrangle
#the data which allows us to group the coursework and homework together
barChart <- wrangled_mycal %>%
mutate(Activity = case_when(str_detect(Activity, "physics") ~ "Physics",
str_detect(Activity, "math") ~ "Math",
str_detect(Activity, "cosc") ~ "Comp Science",
str_detect(Activity, "sleep") ~ "Sleep",
str_detect(Activity, "job") ~ "Job",
str_detect(Activity, "stat") ~ "Statistics",
TRUE ~ "Other"))
#What we want is a barchart that merges both my coursework and homework into
#the same activity, so I used the function 'str_detect' followed by the primary
#keyword which changed the names of those entries in Activities to be the same.
#This would then allow me to group by each course when manipulating the data.
barChart_summarized <- barChart %>%
group_by(Activity) %>%
#Here we're grouping by activity so that we can get the
#cumulative amount of time spent on each of the activites.
summarize(
Total_Time = sum(Duration) #Summation of the duration of all the activites
)
#In the following code, I specifically am wrangling it for the table.
#Notice how I'm piping in mycal and not wrangled_mycal as I did above because
#this time round we need the 'weekday' field
wrangled_table_mycal <- mycal %>%
select(
activity, duration_hours, weekday_number
) %>%
#Here I'm attempting to do a similar wrangling process as the bar chart,
#where I group together the coursework and homework time and then filter
#all rows that aren't 'sleep'
rename(
Activity = activity, Duration = duration_hours,
Weekday = weekday_number) %>%
mutate(Activity = case_when(str_detect(Activity, "physics") ~ "Physics",
str_detect(Activity, "math") ~ "Math",
str_detect(Activity, "cosc") ~ "Comp Science",
str_detect(Activity, "sleep") ~ "Sleep",
str_detect(Activity, "job") ~ "Job",
str_detect(Activity, "stat") ~ "Statistics",
TRUE ~ "Other")) %>%
filter(Activity %in% c("Job", "Physics", "Math", "Comp Science"
,"Statistics"))
summary_table_mycal <- wrangled_table_mycal %>%
group_by(Activity, Weekday) %>%
#Grouping by Activity and Weekday so we can focus on the
#average duration spent on an activity per day
summarize(
Mean_Time = mean(Duration)
) %>%
arrange(Weekday) %>%
mutate(Weekday = case_when(str_detect(Weekday, "1") ~ "Monday",
str_detect(Weekday, "2") ~ "Tuesday",
str_detect(Weekday, "3") ~ "Wednesday",
str_detect(Weekday, "4") ~ "Thursday",
str_detect(Weekday, "5") ~ "Friday",
str_detect(Weekday, "6") ~ "Saturday",
str_detect(Weekday, "7") ~ "Sunday"))
summary_table_mycal$Mean_Time = round(summary_table_mycal$Mean_Time, 1)
#Again, using the case_when with str_detect to substitute numerical days with
#the names of the days
ggplot(homeActivities_plot, aes(x = Activity, y = Duration)) +
geom_boxplot(fill = "white", color = "black") +
theme_minimal() +
coord_flip() +
labs(x = "Activity", y = "Duration (hours)",
title = "Distribution of Duration for Each Activity") +
facet_grid(~Location)
ggplot(barChart_summarized, aes(x = Activity, y = Total_Time)) +
geom_bar(stat = "identity", fill = "white") +
labs(x = "Activity",
y = "Total Duration (hours)",
title = "Total Time Spent on Each Activity") +
theme_dark()
#We're using the wrangling that we did above for summary_table_mycal
pivoted_summary <- summary_table_mycal %>%
pivot_wider(
names_from = Weekday,
values_from = Mean_Time
)
#pivoting allows us to get more columns and thus divide them up into
#weekdays
kable(pivoted_summary, booktabs = TRUE)
#| label: setup
#| include: false
# set code chunk option defaults
knitr::opts_chunk$set(
warning = FALSE,
# display code as types
tidy = FALSE,
# slightly smaller code font
size = "small",
# do not display messages in PDF
message = FALSE,
# set default figure width and height
fig.width = 5, fig.height = 3)
# improve digit and NA display
options(scipen = 1, knitr.kable.NA = '')
# load packages
library(tidyverse)
library(lubridate)
library(ical)
library(kableExtra)
library(janitor)
library(dplyr)
library(stringr)
# do you need more packages?
#| label: gcal-starter-code
#| eval: true #be sure to set this to true and/or just remove
# Data import (requires **ical** package)
cal_import <- ical_parse_df("stat231tracking.ics")
# Data wrangling
mycal <- cal_import %>%
# Google Calendar event names are in a variable called "summary";
# "activity" is a more relevant/informative variable name.
rename(activity = summary) %>%
mutate(
# Specify time zone (defaults to UTC otherwise)
across(c(start, end),
.fns = with_tz,
tzone = "America/New_York"),
# Compute duration of each activity in hours
duration_hours = interval(start, end) / hours(1),
# Examples of getting components of dates/times
# Note:
# i. these could be based on either start datetime or end datetime
# ii. you do NOT need all of these!! so only use what you need
date = date(start),
year = year(start),
month_number = month(start),
month_label = month(start,
label = TRUE,
abbr = FALSE),
weekday_number = wday(start),
weekday_label = wday(start,
label = TRUE,
abbr = FALSE),
hour = hour(start),
time = hour(start) + minute(start)/60,
# Convert text to lowercase and remove repeated or leading/trailing
# spaces to help clean up inconsistent formatting.
across(c(activity, description),
.fns = str_to_lower),
across(c(activity, description),
.fns = str_squish)
) %>%
# The first Google Calendar entry is always an empty 1969 event
filter(year != 1969)
# I have divided my wrangling code into various wrangling sections. The first
# one below is general wrangling code that allows me to select the columns I
# need for my first visualisation and the second one
# (i.e duration spent on activities at home & cumulative time on activities)
wrangled_mycal <- mycal %>%
select(activity, description, duration_hours) %>%
rename(
Activity = activity, Location = description, Duration = duration_hours)
wrangled_mycal$Duration = round(wrangled_mycal$Duration, 3)
#wrangling for first visualisation
homeActivities_plot <- wrangled_mycal %>%
filter(
Activity %in% c("job",
"math211homework",
"physics124homework",
"cosc112homework",
"stat231homework")
) %>%
na.omit()
#Making sure to omit any entries where there was no coursework or
#data was incomplete or missing
#Our second visualisation is in the form of a bar chart, so we must wrangle
#the data which allows us to group the coursework and homework together
barChart <- wrangled_mycal %>%
mutate(Activity = case_when(str_detect(Activity, "physics") ~ "Physics",
str_detect(Activity, "math") ~ "Math",
str_detect(Activity, "cosc") ~ "Comp Science",
str_detect(Activity, "sleep") ~ "Sleep",
str_detect(Activity, "job") ~ "Job",
str_detect(Activity, "stat") ~ "Statistics",
TRUE ~ "Other"))
#What we want is a barchart that merges both my coursework and homework into
#the same activity, so I used the function 'str_detect' followed by the primary
#keyword which changed the names of those entries in Activities to be the same.
#This would then allow me to group by each course when manipulating the data.
barChart_summarized <- barChart %>%
group_by(Activity) %>%
#Here we're grouping by activity so that we can get the
#cumulative amount of time spent on each of the activites.
summarize(
Total_Time = sum(Duration) #Summation of the duration of all the activites
)
#In the following code, I specifically am wrangling it for the table.
#Notice how I'm piping in mycal and not wrangled_mycal as I did above because
#this time round we need the 'weekday' field
wrangled_table_mycal <- mycal %>%
select(
activity, duration_hours, weekday_number
) %>%
#Here I'm attempting to do a similar wrangling process as the bar chart,
#where I group together the coursework and homework time and then filter
#all rows that aren't 'sleep'
rename(
Activity = activity, Duration = duration_hours,
Weekday = weekday_number) %>%
mutate(Activity = case_when(str_detect(Activity, "physics") ~ "Physics",
str_detect(Activity, "math") ~ "Math",
str_detect(Activity, "cosc") ~ "Comp Science",
str_detect(Activity, "sleep") ~ "Sleep",
str_detect(Activity, "job") ~ "Job",
str_detect(Activity, "stat") ~ "Statistics",
TRUE ~ "Other")) %>%
filter(Activity %in% c("Job", "Physics", "Math", "Comp Science"
,"Statistics"))
summary_table_mycal <- wrangled_table_mycal %>%
group_by(Activity, Weekday) %>%
#Grouping by Activity and Weekday so we can focus on the
#average duration spent on an activity per day
summarize(
Mean_Time = mean(Duration)
) %>%
arrange(Weekday) %>%
mutate(Weekday = case_when(str_detect(Weekday, "1") ~ "Monday",
str_detect(Weekday, "2") ~ "Tuesday",
str_detect(Weekday, "3") ~ "Wednesday",
str_detect(Weekday, "4") ~ "Thursday",
str_detect(Weekday, "5") ~ "Friday",
str_detect(Weekday, "6") ~ "Saturday",
str_detect(Weekday, "7") ~ "Sunday"))
summary_table_mycal$Mean_Time = round(summary_table_mycal$Mean_Time, 1)
#Again, using the case_when with str_detect to substitute numerical days with
#the names of the days
#The ggplot code alongside geom_boxplot allows us to plot a boxplot.
#aes determines what our x and y coordinates will be
#faceting allows us to divide the data by location into separate graphs
#labs allows us to label our axes
ggplot(homeActivities_plot, aes(x = Activity, y = Duration)) +
geom_boxplot(fill = "white", color = "black") +
theme_minimal() + #Minimalism
coord_flip() +
labs(x = "Activity", y = "Duration (hours)",
title = "Distribution of Duration for Each Activity") +
facet_grid(~Location) #faceting
#The ggplot code alongside geom_bar allows us to plot a barchart
#aes determines what our x and y coordinates will be
#labs allows us to label our axes
ggplot(barChart_summarized, aes(x = Activity, y = Total_Time)) +
geom_bar(stat = "identity", fill = "white") +
labs(x = "Activity",
y = "Total Duration (hours)",
title = "Total Time Spent on Each Activity") +
theme_dark() #DarkMode has been set
#We're using the wrangling that we did above for summary_table_mycal
pivoted_summary <- summary_table_mycal %>%
pivot_wider(
names_from = Weekday,
values_from = Mean_Time
)
#pivoting allows us to get more columns and thus divide them up into
#weekdays
kable(pivoted_summary, booktabs = TRUE)
#| label: setup
#| include: false
# set code chunk option defaults
knitr::opts_chunk$set(
warning = FALSE,
# display code as types
tidy = FALSE,
# slightly smaller code font
size = "small",
# do not display messages in PDF
message = FALSE,
# set default figure width and height
fig.width = 5, fig.height = 3)
# improve digit and NA display
options(scipen = 1, knitr.kable.NA = '')
# load packages
library(tidyverse)
library(lubridate)
library(ical)
library(kableExtra)
library(janitor)
library(dplyr)
library(stringr)
#Importing dataset of covid cases
casesCountryData <- read_csv("COVID Datasets/dailyCases.csv")
casesCountryDataSelected <- casesCountryData %>%
select(cases, deaths, countriesAndTerritories)
#Since the cases dataset is of daily cases per country in the year 2020, we are going to have to summarise the data and group by country
casesCountryDataSummarized <- casesCountryDataSelected %>%
group_by(countriesAndTerritories) %>%
summarise(
Cases = sum(cases)
)
head(casesCountryDataSummarized)
#Importing dataset of covid cases
casesCountryData <- read_csv("COVID Datasets/dailyCases.csv")
casesCountryDataSelected <- casesCountryData %>%
select(cases, deaths, countriesAndTerritories)
#Since the cases dataset is of daily cases per country in the year 2020, we are going to have to summarise the data and group by country
casesCountryDataSummarized <- casesCountryDataSelected %>%
group_by(countriesAndTerritories) %>%
summarise(
Cases = sum(cases)
)
kable(casesCountryDataSummarized)
#Importing dataset of covid cases
casesCountryData <- read_csv("COVID Datasets/dailyCases.csv")
casesCountryDataSelected <- casesCountryData %>%
select(cases, deaths, countriesAndTerritories)
#Since the cases dataset is of daily cases per country in the year 2020, we are going to have to summarise the data and group by country
casesCountryDataSummarized <- casesCountryDataSelected %>%
group_by(countriesAndTerritories) %>%
summarise(
Cases = sum(cases)
)
top_5 <- head(df, n = 5)
kable(top_5)
#Importing dataset of covid cases
casesCountryData <- read_csv("COVID Datasets/dailyCases.csv")
casesCountryDataSelected <- casesCountryData %>%
select(cases, deaths, countriesAndTerritories)
#Since the cases dataset is of daily cases per country in the year 2020, we are going to have to summarise the data and group by country
casesCountryDataSummarized <- casesCountryDataSelected %>%
group_by(countriesAndTerritories) %>%
summarise(
Cases = sum(cases)
)
top_5 <- head(casesCountryDataSummarized, n = 5)
kable(top_5)
#Importing dataset of covid cases
casesCountryData <- read_csv("COVID Datasets/dailyCases.csv")
casesCountryDataSelected <- casesCountryData %>%
select(cases, deaths, countriesAndTerritories)
#Since the cases dataset is of daily cases per country in the year 2020, we are going to have to summarise the data and group by country
casesCountryDataSummarized <- casesCountryDataSelected %>%
group_by(countriesAndTerritories) %>%
summarise(
Cases = sum(cases)
)
top_5 <- head(casesCountryDataSummarized, n = 5)
kable(top_5)
CorrectedNames <- read_csv("COVID Datasets/CountryDataSummarizedCorrectedNames.csv")
#Merging the datasets into one so we have a country with its designated latitude and longitude alongside their cases
casesCountryLatLong <- left_join(CorrectedNames, latitudelongitudeData, by = c("Countries" = "Country"))
#Importing corrected Names dataset
CorrectedNames <- read_csv("COVID Datasets/CountryDataSummarizedCorrectedNames.csv")
#Importing dataset of latitudes and longitudes of each country, and getting rid of country codes
latitudelongitudeData <- read_csv("COVID Datasets/latlong.csv") %>%
select(Country, Latitude, Longitude)
#Merging the datasets into one so we have a country with its designated latitude and longitude alongside their cases
casesCountryLatLong <- left_join(CorrectedNames, latitudelongitudeData, by = c("Countries" = "Country"))
kable(head(casesCountryLatLong, 5))
#Importing corrected Names dataset
CorrectedNames <- read_csv("COVID Datasets/CountryDataSummarizedCorrectedNames.csv")
#Importing dataset of latitudes and longitudes of each country, and getting rid of country codes
latitudelongitudeData <- read_csv("COVID Datasets/latlong.csv") %>%
select(Country, Latitude, Longitude)
#Merging the datasets into one so we have a country with its designated latitude and longitude alongside their cases
casesCountryLatLong <- left_join(CorrectedNames, latitudelongitudeData, by = c("Countries" = "Country"))
kable(head(casesCountryLatLong, 5))
topicAnalysisData <- read_excel("COVID Datasets/topicAnalysisData.xlsx")
topicAnalysisData <- readRDS("COVID Datasets/topicAnalysisDataSelected.rds")
topicAnalysisData <- readRDS("COVID Datasets/topicAnalysisData.rds")
topicAnalysisData <- readRDS("COVID Datasets/LDAtopicAnalysisData.rds")
topicAnalysisData <- readRDS("COVID Datasets/LDATopicAnalysisData.rds")
topicAnalysisData <- readRDS("COVID Datasets/LDATopicAnalysisData.rds")
topicAnalysisData <- readRDS("COVID Datasets/LDATopicAnalysisData.rds")
topicAnalysisData <- readRDS("Sasved RDS Files/LDATopicAnalysisData.rds")
topicAnalysisData <- readRDS("Sasved RDS Files/LDATopicAnalysisData.rds")
topicAnalysisData <- readRDS("Sasved RDS Files/LDATopicAnalysisData.rds")
LDAAnalysisDataset <- readRDS("Saved RDS Files/LDATopicAnalysisData.rds")
#| label: setup
#| include: false
# set code chunk option defaults
knitr::opts_chunk$set(
warning = FALSE,
# display code as types
tidy = FALSE,
# slightly smaller code font
size = "small",
# do not display messages in PDF
message = FALSE,
# set default figure width and height
fig.width = 5, fig.height = 3)
# improve digit and NA display
options(scipen = 1, knitr.kable.NA = '')
# load packages
library(tidyverse)
library(lubridate)
library(ical)
library(kableExtra)
library(janitor)
library(dplyr)
library(stringr)
#Importing dataset of covid cases
casesCountryData <- read_csv("COVID Datasets/dailyCases.csv")
casesCountryDataSelected <- casesCountryData %>%
select(cases, deaths, countriesAndTerritories)
#Since the cases dataset is of daily cases per country in the year 2020, we are going to have to summarise the data and group by country
casesCountryDataSummarized <- casesCountryDataSelected %>%
group_by(countriesAndTerritories) %>%
summarise(
Cases = sum(cases)
)
top_5 <- head(casesCountryDataSummarized, n = 5)
kable(top_5)
#| label: setup
#| include: false
# set code chunk option defaults
knitr::opts_chunk$set(
warning = FALSE,
# display code as types
tidy = FALSE,
# slightly smaller code font
size = "small",
# do not display messages in PDF
message = FALSE,
# set default figure width and height
fig.width = 5, fig.height = 3)
# improve digit and NA display
options(scipen = 1, knitr.kable.NA = '')
# load packages
library(tidyverse)
library(lubridate)
library(ical)
library(kableExtra)
library(janitor)
library(dplyr)
library(stringr)
#Importing dataset of covid cases
casesCountryData <- read_csv("COVID Datasets/dailyCases.csv")
casesCountryDataSelected <- casesCountryData %>%
select(cases, deaths, countriesAndTerritories)
#Since the cases dataset is of daily cases per country in the year 2020, we are going to have to summarise the data and group by country
casesCountryDataSummarized <- casesCountryDataSelected %>%
group_by(countriesAndTerritories) %>%
summarise(
Cases = sum(cases)
)
top_5 <- head(casesCountryDataSummarized, n = 5)
kable(top_5)
#Importing corrected Names dataset
CorrectedNames <- read_csv("COVID Datasets/CountryDataSummarizedCorrectedNames.csv")
#Importing dataset of latitudes and longitudes of each country, and getting rid of country codes
latitudelongitudeData <- read_csv("COVID Datasets/latlong.csv") %>%
select(Country, Latitude, Longitude)
#Merging the datasets into one so we have a country with its designated latitude and longitude alongside their cases
casesCountryLatLong <- left_join(CorrectedNames, latitudelongitudeData, by = c("Countries" = "Country"))
kable(head(casesCountryLatLong, 5))
LDAAnalysisDataset <- readRDS("Saved RDS Files/LDATopicAnalysisData.rds")
View(LDAAnalysisDataset)
LDAAnalysisDataset <- readRDS("Saved RDS Files/LDATopicAnalysisData.rds")
kable(head(LDAAnalysisDataset, 5))
LDAAnalysisDataset <- readRDS("Saved RDS Files/LDATopicAnalysisData.rds")
kable(head(LDAAnalysisDataset, 1))
LDAAnalysisDataset <- readRDS("Saved RDS Files/LDATopicAnalysisData.rds")
sample <- LDAAnalysisDataset %>%
select(Title, Primary_Country)
kable(head(LDAAnalysisDataset, 1))
LDAAnalysisDataset <- readRDS("Saved RDS Files/LDATopicAnalysisData.rds")
sample <- LDAAnalysisDataset %>%
select(Title, Primary_Country)
kable(head(sample, 1))
LDAAnalysisDataset <- readRDS("Saved RDS Files/LDATopicAnalysisData.rds")
sample <- LDAAnalysisDataset %>%
select(Title, Primary_Country, Publication_Date)
kable(head(sample, 1))
library(shiny); runApp('~/GitHub/stat231bilal/Projects/final-project/Shiny Leaflet Map - COVID Cases.R')
