---
title: "LDA Topic Analysis"
author: "Bilal Tariq"
date: "2024-04-29"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(topicmodels)
library(kableExtra)
library(tm)
library(janitor)
library(tidytext)
library(wordcloud)
library(textdata)
library(reshape2)
```

Here we're trying to load the RDS file for text analysis that we saved during Data Wrangling

```{r pressure, echo = TRUE}

LDAAnalysisDataset <- readRDS("Saved RDS Files/LDATopicAnalysisData.rds") 

#Tokenizing the text

tokenizedLDADataset <- LDAAnalysisDataset %>%
  unnest_tokens(output = word, input = Title) %>%
  select(Primary_Country, word)

# Filter out words like "COVID" and "19" and "coronavirus"
filterWords <- c("covid", "19", "coronavirus")

tokenizedLDADataset_filtered <- tokenizedLDADataset %>%
  filter(!word %in% filterWords) %>%
  select(Primary_Country, word)

#Getting rid of the stop words

data(stop_words)

tokenizedLDADataset_stopped <- tokenizedLDADataset_filtered %>%
  anti_join(stop_words, by = "word")

#Now we're trying to convert tokenized data to a Document-Term Matrix

dtm <- tokenizedLDADataset_stopped %>%
  count(Primary_Country, word) %>%
  cast_dtm(Primary_Country, word, n)

#Specifying the number of topics we want for our first analysis

analysisLDA <- LDA(dtm, 6, method = "Gibbs", control = list(seed = 231))

topics <- tidy(analysisLDA, matrix = "beta")
head(topics)

topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()


#covid_lda <- LDA(tokenizedLDADataset_stopped, k = 2, control = list(seed = 1234))

```

I also decided it might be interesting to see COVID misinformation in areas where there were high cases and different geographical locations:

```{r pressure, echo= TRUE}

indiaLDAdataset <- tokenizedLDADataset_stopped %>%
  filter(Primary_Country == "India")

dtmINDIA <- indiaLDAdataset %>%
  count(Primary_Country, word) %>%
  cast_dtm(Primary_Country, word, n)

#Specifying the number of topics we want for our country analysis

analysisLDAINDIA <- LDA(dtmINDIA, 3, method = "Gibbs", control = list(seed = 231))

topicsINDIA <- tidy(analysisLDAINDIA, matrix = "beta")
head(topics)

topicsINDIA %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()

################

USLDAdataset <- tokenizedLDADataset_stopped %>%
  filter(Primary_Country == "US")

dtmUS <- USLDAdataset %>%
  count(Primary_Country, word) %>%
  cast_dtm(Primary_Country, word, n)

#Specifying the number of topics we want for our country analysis

analysisLDAUS <- LDA(dtmUS, 3, method = "Gibbs", control = list(seed = 123))

topicsUS <- tidy(analysisLDAUS, matrix = "beta")
head(topics)

topicsUS %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()


################

PakistanLDAdataset <- tokenizedLDADataset_stopped %>%
  filter(Primary_Country == "Pakistan")

dtmPAKISTAN <- MalaysiaLDAdataset %>%
  count(Primary_Country, word) %>%
  cast_dtm(Primary_Country, word, n)

#Specifying the number of topics we want for our country analysis

analysisLDAPakistan <- LDA(dtmPAKISTAN, 3, method = "Gibbs", control = list(seed = 123))

topicsPakistan <- tidy(analysisLDAPakistan, matrix = "beta")
head(topics)

topicsPakistan %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()



```

```{r pressure, echo = TRUE}



```
